{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b114b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9663aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric-f https://data.pyg.org/whl/torch-1.10.0+cu113.html\\n\\nhttps://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First install dependences to pytorch geometric\n",
    "\"\"\"\n",
    "pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric-f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c04589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0.html\n",
    "# pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0.html\n",
    "# pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c7d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the librarys\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703626c0",
   "metadata": {},
   "source": [
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html"
   ]
  },
  {
   "attachments": {
    "graph.svg": {
     "image/svg+xml": [
      "<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="152.792pt" height="60.915pt" viewBox="0 0 152.792 60.915" version="1.1">
<defs>
<g>
<symbol overflow="visible" id="glyph0-0">
<path style="stroke:none;" d=""/>
</symbol>
<symbol overflow="visible" id="glyph0-1">
<path style="stroke:none;" d="M 4.578125 -3.1875 C 4.578125 -3.984375 4.53125 -4.78125 4.1875 -5.515625 C 3.734375 -6.484375 2.90625 -6.640625 2.5 -6.640625 C 1.890625 -6.640625 1.171875 -6.375 0.75 -5.453125 C 0.4375 -4.765625 0.390625 -3.984375 0.390625 -3.1875 C 0.390625 -2.4375 0.421875 -1.546875 0.84375 -0.78125 C 1.265625 0.015625 2 0.21875 2.484375 0.21875 C 3.015625 0.21875 3.78125 0.015625 4.21875 -0.9375 C 4.53125 -1.625 4.578125 -2.40625 4.578125 -3.1875 Z M 2.484375 0 C 2.09375 0 1.5 -0.25 1.328125 -1.203125 C 1.21875 -1.796875 1.21875 -2.71875 1.21875 -3.3125 C 1.21875 -3.953125 1.21875 -4.609375 1.296875 -5.140625 C 1.484375 -6.328125 2.234375 -6.421875 2.484375 -6.421875 C 2.8125 -6.421875 3.46875 -6.234375 3.65625 -5.25 C 3.765625 -4.6875 3.765625 -3.9375 3.765625 -3.3125 C 3.765625 -2.5625 3.765625 -1.890625 3.65625 -1.25 C 3.5 -0.296875 2.9375 0 2.484375 0 Z M 2.484375 0 "/>
</symbol>
<symbol overflow="visible" id="glyph0-2">
<path style="stroke:none;" d="M 6.84375 -3.265625 C 7 -3.265625 7.1875 -3.265625 7.1875 -3.453125 C 7.1875 -3.65625 7 -3.65625 6.859375 -3.65625 L 0.890625 -3.65625 C 0.75 -3.65625 0.5625 -3.65625 0.5625 -3.453125 C 0.5625 -3.265625 0.75 -3.265625 0.890625 -3.265625 Z M 6.859375 -1.328125 C 7 -1.328125 7.1875 -1.328125 7.1875 -1.53125 C 7.1875 -1.71875 7 -1.71875 6.84375 -1.71875 L 0.890625 -1.71875 C 0.75 -1.71875 0.5625 -1.71875 0.5625 -1.53125 C 0.5625 -1.328125 0.75 -1.328125 0.890625 -1.328125 Z M 6.859375 -1.328125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-3">
<path style="stroke:none;" d="M 2.9375 -6.375 C 2.9375 -6.625 2.9375 -6.640625 2.703125 -6.640625 C 2.078125 -6 1.203125 -6 0.890625 -6 L 0.890625 -5.6875 C 1.09375 -5.6875 1.671875 -5.6875 2.1875 -5.953125 L 2.1875 -0.78125 C 2.1875 -0.421875 2.15625 -0.3125 1.265625 -0.3125 L 0.953125 -0.3125 L 0.953125 0 C 1.296875 -0.03125 2.15625 -0.03125 2.5625 -0.03125 C 2.953125 -0.03125 3.828125 -0.03125 4.171875 0 L 4.171875 -0.3125 L 3.859375 -0.3125 C 2.953125 -0.3125 2.9375 -0.421875 2.9375 -0.78125 Z M 2.9375 -6.375 "/>
</symbol>
<symbol overflow="visible" id="glyph0-4">
<path style="stroke:none;" d="M 1.265625 -0.765625 L 2.328125 -1.796875 C 3.875 -3.171875 4.46875 -3.703125 4.46875 -4.703125 C 4.46875 -5.84375 3.578125 -6.640625 2.359375 -6.640625 C 1.234375 -6.640625 0.5 -5.71875 0.5 -4.828125 C 0.5 -4.28125 1 -4.28125 1.03125 -4.28125 C 1.203125 -4.28125 1.546875 -4.390625 1.546875 -4.8125 C 1.546875 -5.0625 1.359375 -5.328125 1.015625 -5.328125 C 0.9375 -5.328125 0.921875 -5.328125 0.890625 -5.3125 C 1.109375 -5.96875 1.65625 -6.328125 2.234375 -6.328125 C 3.140625 -6.328125 3.5625 -5.515625 3.5625 -4.703125 C 3.5625 -3.90625 3.078125 -3.125 2.515625 -2.5 L 0.609375 -0.375 C 0.5 -0.265625 0.5 -0.234375 0.5 0 L 4.203125 0 L 4.46875 -1.734375 L 4.234375 -1.734375 C 4.171875 -1.4375 4.109375 -1 4 -0.84375 C 3.9375 -0.765625 3.28125 -0.765625 3.0625 -0.765625 Z M 1.265625 -0.765625 "/>
</symbol>
<symbol overflow="visible" id="glyph1-0">
<path style="stroke:none;" d=""/>
</symbol>
<symbol overflow="visible" id="glyph1-1">
<path style="stroke:none;" d="M 3.328125 -3.015625 C 3.390625 -3.265625 3.625 -4.1875 4.3125 -4.1875 C 4.359375 -4.1875 4.609375 -4.1875 4.8125 -4.0625 C 4.53125 -4 4.34375 -3.765625 4.34375 -3.515625 C 4.34375 -3.359375 4.453125 -3.171875 4.71875 -3.171875 C 4.9375 -3.171875 5.25 -3.34375 5.25 -3.75 C 5.25 -4.265625 4.671875 -4.40625 4.328125 -4.40625 C 3.75 -4.40625 3.40625 -3.875 3.28125 -3.65625 C 3.03125 -4.3125 2.5 -4.40625 2.203125 -4.40625 C 1.171875 -4.40625 0.59375 -3.125 0.59375 -2.875 C 0.59375 -2.765625 0.703125 -2.765625 0.71875 -2.765625 C 0.796875 -2.765625 0.828125 -2.796875 0.84375 -2.875 C 1.1875 -3.9375 1.84375 -4.1875 2.1875 -4.1875 C 2.375 -4.1875 2.71875 -4.09375 2.71875 -3.515625 C 2.71875 -3.203125 2.546875 -2.546875 2.1875 -1.140625 C 2.03125 -0.53125 1.671875 -0.109375 1.234375 -0.109375 C 1.171875 -0.109375 0.953125 -0.109375 0.734375 -0.234375 C 0.984375 -0.296875 1.203125 -0.5 1.203125 -0.78125 C 1.203125 -1.046875 0.984375 -1.125 0.84375 -1.125 C 0.53125 -1.125 0.296875 -0.875 0.296875 -0.546875 C 0.296875 -0.09375 0.78125 0.109375 1.21875 0.109375 C 1.890625 0.109375 2.25 -0.59375 2.265625 -0.640625 C 2.390625 -0.28125 2.75 0.109375 3.34375 0.109375 C 4.375 0.109375 4.9375 -1.171875 4.9375 -1.421875 C 4.9375 -1.53125 4.859375 -1.53125 4.828125 -1.53125 C 4.734375 -1.53125 4.71875 -1.484375 4.6875 -1.421875 C 4.359375 -0.34375 3.6875 -0.109375 3.375 -0.109375 C 2.984375 -0.109375 2.828125 -0.421875 2.828125 -0.765625 C 2.828125 -0.984375 2.875 -1.203125 2.984375 -1.640625 Z M 3.328125 -3.015625 "/>
</symbol>
<symbol overflow="visible" id="glyph2-0">
<path style="stroke:none;" d=""/>
</symbol>
<symbol overflow="visible" id="glyph2-1">
<path style="stroke:none;" d="M 2.328125 -4.4375 C 2.328125 -4.625 2.328125 -4.625 2.125 -4.625 C 1.671875 -4.1875 1.046875 -4.1875 0.765625 -4.1875 L 0.765625 -3.9375 C 0.921875 -3.9375 1.390625 -3.9375 1.765625 -4.125 L 1.765625 -0.578125 C 1.765625 -0.34375 1.765625 -0.25 1.078125 -0.25 L 0.8125 -0.25 L 0.8125 0 C 0.9375 0 1.796875 -0.03125 2.046875 -0.03125 C 2.265625 -0.03125 3.140625 0 3.296875 0 L 3.296875 -0.25 L 3.03125 -0.25 C 2.328125 -0.25 2.328125 -0.34375 2.328125 -0.578125 Z M 2.328125 -4.4375 "/>
</symbol>
<symbol overflow="visible" id="glyph3-0">
<path style="stroke:none;" d=""/>
</symbol>
<symbol overflow="visible" id="glyph3-1">
<path style="stroke:none;" d="M 6.5625 -2.296875 C 6.734375 -2.296875 6.921875 -2.296875 6.921875 -2.5 C 6.921875 -2.6875 6.734375 -2.6875 6.5625 -2.6875 L 1.171875 -2.6875 C 1 -2.6875 0.828125 -2.6875 0.828125 -2.5 C 0.828125 -2.296875 1 -2.296875 1.171875 -2.296875 Z M 6.5625 -2.296875 "/>
</symbol>
</g>
<clipPath id="clip1">
  <path d="M 37 37 L 67 37 L 67 60.914062 L 37 60.914062 Z M 37 37 "/>
</clipPath>
<clipPath id="clip2">
  <path d="M 94 37 L 123 37 L 123 60.914062 L 94 60.914062 Z M 94 37 "/>
</clipPath>
</defs>
<g id="surface1">
<g clip-path="url(#clip1)" clip-rule="nonzero">
<path style="fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 8.708813 0.0001875 C 8.708813 4.808781 4.810375 8.707219 0.00178125 8.707219 C -4.810719 8.707219 -8.709156 4.808781 -8.709156 0.0001875 C -8.709156 -4.808406 -4.810719 -8.706844 0.00178125 -8.706844 C 4.810375 -8.706844 8.708813 -4.808406 8.708813 0.0001875 Z M 8.708813 0.0001875 " transform="matrix(1,0,0,-1,51.924,52.008)"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-1" x="49.433" y="55.218"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph1-1" x="3.321" y="54.471"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph2-1" x="9.014" y="55.966"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-2" x="16.251" y="54.471"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph3-1" x="26.767" y="54.471"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-3" x="34.516" y="54.471"/>
</g>
<path style="fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 37.052563 28.347844 C 37.052563 33.156437 33.154125 37.054875 28.345531 37.054875 C 23.536938 37.054875 19.6385 33.156437 19.6385 28.347844 C 19.6385 23.53925 23.536938 19.640812 28.345531 19.640812 C 33.154125 19.640812 37.052563 23.53925 37.052563 28.347844 Z M 37.052563 28.347844 " transform="matrix(1,0,0,-1,51.924,52.008)"/>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-3" x="77.78" y="26.872"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph1-1" x="66.056" y="9.741"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph2-1" x="71.75" y="11.235"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-2" x="78.987" y="9.741"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-1" x="89.505513" y="9.741"/>
</g>
<g clip-path="url(#clip2)" clip-rule="nonzero">
<path style="fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 65.400219 0.0001875 C 65.400219 4.808781 61.501781 8.707219 56.693188 8.707219 C 51.884594 8.707219 47.986156 4.808781 47.986156 0.0001875 C 47.986156 -4.808406 51.884594 -8.706844 56.693188 -8.706844 C 61.501781 -8.706844 65.400219 -4.808406 65.400219 0.0001875 Z M 65.400219 0.0001875 " transform="matrix(1,0,0,-1,51.924,52.008)"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-4" x="106.126" y="55.218"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph1-1" x="121.043" y="54.471"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph2-1" x="126.737" y="55.966"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-2" x="133.974" y="54.471"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-3" x="144.492513" y="54.471"/>
</g>
<path style="fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 6.298656 6.297062 L 22.048656 22.047062 " transform="matrix(1,0,0,-1,51.924,52.008)"/>
<path style="fill:none;stroke-width:0.3985;stroke-linecap:butt;stroke-linejoin:miter;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 34.646313 22.047062 L 50.396313 6.297062 " transform="matrix(1,0,0,-1,51.924,52.008)"/>
</g>
</svg>
"
     ]
    }
   },
   "cell_type": "markdown",
   "id": "b978a6a6",
   "metadata": {},
   "source": [
    "![graph.svg](attachment:graph.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6eb8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 2],\n",
       "        [1, 0, 2, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Represents the edges at the graph above\n",
    "where first row represent one way to conecte(like 0 to 1)\n",
    "and second row the 'back' with (1 to 0).\n",
    "\"\"\"\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5140693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0],\n",
       "        [1, 2],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can write the edge index like a tensor off pairs\n",
    "using edge_index.contiguous()\n",
    "\"\"\"\n",
    "edge_index.t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330cfa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X represetns the value of some metric to each node\n",
    "following the numeric order of node (0,1,2 like in the example)\n",
    "\"\"\"\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835b80a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[4, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee5be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes at the graph: 3\n",
      "Number of edges at the graph: 2\n",
      "Number of features (metrics) at the graph 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Some tips of commands that help us to verify if the graph is correctly contructed\n",
    "and how send this data to GPU for training (in future)\n",
    "\"\"\"\n",
    "print(f\"Number of nodes at the graph: {data.num_nodes}\")\n",
    "\n",
    "print(f\"Number of edges at the graph: {data.num_edges}\")\n",
    "\n",
    "print(f\"Number of features (metrics) at the graph {data.num_node_features}\")\n",
    "\n",
    "# Transfer data object to GPU.\n",
    "device = torch.device('cuda')\n",
    "#Come back data to CPU\n",
    "data = data.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ecd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a6a85c",
   "metadata": {},
   "source": [
    "### Example with Protein dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302edb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "# https://chrsmrrs.github.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8274f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the enzine dataset that are compost with 600 graphs with 6 classes\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c865ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 600\n",
      "Number of classes: 6\n",
      "Features per node: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of dataset: {len(dataset)}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Features per node: {dataset.num_node_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bda38eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 128], x=[33, 3], y=[1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Acessing the first graph at the dataset we can see that have\n",
    "84 undirect edges (168/2), with 33 nodes where each node gave\n",
    "3 feature value and the classe of this graph is 1 (y value)\n",
    "\"\"\"\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cecfb27",
   "metadata": {},
   "source": [
    "### Separing data in training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa8e921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting the training set with 90% of data and test with 10%\n",
    "\"\"\"\n",
    "#How much samples will have in traing\n",
    "numb_traing_samples = int(len(dataset) * 0.9)\n",
    "\n",
    "#Shuffling the dataset\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "#Defining how are the traing\n",
    "train_dataset = dataset[:numb_traing_samples]\n",
    "\n",
    "#And choosen the test\n",
    "test_dataset = dataset[numb_traing_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70edc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3ffeb36",
   "metadata": {},
   "source": [
    "## Creating DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65aab82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66e06d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataloader is the structure responsable to generate the batchs for network,\n",
    "when called return a set of graphs (the batch size)\n",
    "\"\"\"\n",
    "loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bde95cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 3912], x=[1002, 3], y=[32], batch=[1002], ptr=[33])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Way to see what return at each interaction in dataloader\n",
    "#The variable batch shows the index of each node at the batch\n",
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "baeb5f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each batch have: 1956 edges, 1002 nodes with 3 features each\n"
     ]
    }
   ],
   "source": [
    "print(f\"Each batch have: {int(3912/2)} edges, 1002 nodes with 3 features each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d9cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd9f5498",
   "metadata": {},
   "source": [
    "## Network (GCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2a6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c16c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the GCN convolutional network, with 2 convolutional layers\n",
    "with activation ReLU and softmax activation for total of classes.\n",
    "\"\"\"\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(train_dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, train_dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1dde1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a GPU and cuda installed this part set to use GPU in training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = loader\n",
    "\n",
    "#Select how optimizer will be used to adjust the network weights\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db33fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b16a0c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "854cd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "998227e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aba58980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ..., 31, 31, 31])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66a797c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 0.0000, 0.4444, 0.5556, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4750, 0.5250, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3448, 0.6552, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4872, 0.5128, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5227, 0.4773, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3793, 0.6207, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4615, 0.5385, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4800, 0.5200, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.6061, 0.3939, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.2727, 0.7273, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3333, 0.6667, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.7059, 0.2941, 0.0000],\n",
       "        [1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5385, 0.4615, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5556, 0.4444, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5714, 0.4286, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5000, 0.5000, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4524, 0.5476, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 0.3000, 0.2500, 0.4500],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3846, 0.6154, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.8000, 0.2000, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.7273, 0.2727, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5556, 0.4444, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3947, 0.6053, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3913, 0.6087, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3077, 0.6923, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.4857, 0.5143, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.6364, 0.3636, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.7826, 0.2174, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5455, 0.4545, 0.0000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.6486, 0.3514, 0.0000]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([gmp(a.x, a.batch), gap(a.x, a.batch)],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975089d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[539].x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aeb512dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(next(iter(loader)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b71486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "90ef48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1021, 6])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "68662a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff87c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b54934e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 128], x=[33, 3], y=[1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3f6755e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1021) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7196/2945779813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Calculate the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m#Do the backpropragation (adjusting the weight of layers)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\stiva\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2532\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1021) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "#Set the model in training model (use the forward function of the class)\n",
    "#and adjust the weights value after each epoch\n",
    "model.train()\n",
    "\n",
    "for data in loader:\n",
    "    #Inforns that optimizer need a gradient values adjust\n",
    "    optimizer.zero_grad()\n",
    "    #Get the result of network (softmax output)\n",
    "    out = model(data.to(device))\n",
    "    #Calculate the loss\n",
    "    loss = F.nll_loss(out, data.y)\n",
    "    #Do the backpropragation (adjusting the weight of layers)\n",
    "    loss.backward()\n",
    "    #Set the new weights and got to next step\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
